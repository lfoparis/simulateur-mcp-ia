import streamlit as st
from openai import OpenAI
import uuid
from db_utils import init_db, save_message, load_messages

st.set_page_config(page_title="Simulateur MCP avec IA", page_icon="ðŸ¤–")
st.title("ðŸ’¬ Simulateur MCP avec IA (enregistrement SQLite)")

# ðŸ” ClÃ© OpenAI
api_key = st.text_input("ðŸ”‘ Ta clÃ© OpenAI :", type="password")

# ðŸ§± Initialiser la base si besoin
init_db()

# ðŸ§  CrÃ©ation du client OpenAI
if api_key:
    client = OpenAI(api_key=api_key)

    # ðŸ§‘ Message client
    question = st.text_input("ðŸ§‘ Message du client :")

    if st.button("Envoyer") and question.strip():
        try:
            # ðŸ“¡ Appel IA
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Tu es un assistant francophone utile."},
                    {"role": "user", "content": question}
                ]
            )
            answer = response.choices[0].message.content

            # ðŸ’¾ Sauvegarde en base SQLite
            message_id = str(uuid.uuid4())
            save_message(message_id, "client_web", question, answer, "gpt-3.5-turbo")

            st.success("ðŸŸ£ RÃ©ponse du serveur IA :")
            st.markdown(f"> {answer}")

        except Exception as e:
            st.error(f"Erreur IA : {str(e)}")

# ðŸ“œ Historique
with st.expander("ðŸ“„ Historique enregistrÃ© (base SQLite)", expanded=True):
    rows = load_messages()
    if rows:
        for ts, sender, q, r in rows:
            st.markdown(f"**ðŸ•’ {ts} - {sender}**")
            st.markdown(f"- **Q :** {q}")
            st.markdown(f"- **R :** {r}")
            st.markdown("---")
    else:
        st.info("Aucun Ã©change encore enregistrÃ©.")
